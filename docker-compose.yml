services:
  postgres_dev:
    image: pgvector/pgvector:pg16
    container_name: postgres_dev
    restart: unless-stopped
    ports:
      - "${POSTGRES_HOST_PORT:-5432}:5432"
    env_file:
      - .env.postgres
    environment:
      POSTGRES_DB: ${POSTGRES_DB:-ragdb}
      POSTGRES_USER: ${POSTGRES_USER:-rag}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-ragpassword}
    volumes:
      - pgdata:/var/lib/postgresql/data
    healthcheck:
      test:
        ["CMD-SHELL", 'pg_isready -U "$${POSTGRES_USER}" -d "$${POSTGRES_DB}"']
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    security_opt:
      - no-new-privileges:true
    deploy:
      resources:
        limits:
          cpus: "1.0"
          memory: 1G
        reservations:
          memory: 256M

  backend_dev:
    build:
      context: .
      dockerfile: deploy/containers/Dockerfile.backend
      tags:
        - rag-backend:dev
      platforms:
        - linux/arm64
    container_name: backend_dev
    restart: unless-stopped
    ports:
      - "8000:8000"
    env_file:
      - backend/.env
      - .env.postgres
    environment:
      TEI_BASE_URL: http://embedding_dev:80
      LOCAL_LLM_BASE_URL: http://llm_dev:8000/v1
    platform: linux/arm64
    volumes:
      - ./backend/pdfs:/app/pdfs
      - ./backend:/app
    depends_on:
      - postgres_dev
      - embedding_dev
      - llm_dev
    cap_drop: ["ALL"]
    security_opt:
      - no-new-privileges:true
    read_only: true
    deploy:
      resources:
        limits:
          cpus: "2.0"
          memory: 2G
        reservations:
          memory: 512M

  frontend_dev:
    build:
      context: .
      dockerfile: deploy/containers/Dockerfile.frontend
      tags:
        - rag-frontend:dev
      platforms:
        - linux/arm64
      args:
        VITE_API_URL: http://backend_dev:8000
    container_name: frontend_dev
    restart: unless-stopped
    ports:
      - "8080:8080"
    platform: linux/arm64
    environment:
      BACKEND_URL: http://backend_dev:8000
    depends_on:
      - backend_dev
    cap_drop: ["ALL"]
    security_opt:
      - no-new-privileges:true
    deploy:
      resources:
        limits:
          cpus: "1.0"
          memory: 512M
        reservations:
          memory: 128M

  embedding_dev:
    image: ghcr.io/huggingface/text-embeddings-inference:cpu-1.8
    platform: linux/amd64
    container_name: embedding_dev
    restart: unless-stopped
    ports:
      - "7070:80"
    volumes:
      - type: bind
        source: ${TEI_MODEL_DIR:-$HOME/rag-tei/models}
        read_only: true
        target: /data
    environment:
      MODEL_ID: /data/nomic-embed-text-v1.5
    cap_drop: ["ALL"]
    security_opt:
      - no-new-privileges:true
    read_only: true
    deploy:
      resources:
        limits:
          cpus: "10.0"
          memory: 17G
        reservations:
          memory: 4G

  llm_dev:
    build:
      context: .
      dockerfile: deploy/containers/Dockerfile.llamacpp
    container_name: llm_dev
    restart: unless-stopped
    ports:
      - "8081:8000"
    environment:
      HOST: 0.0.0.0
      PORT: 8000
    security_opt:
      - no-new-privileges:true
    read_only: true
    deploy:
      resources:
        limits:
          cpus: "10.0"
          memory: 4G
        reservations:
          memory: 2G

networks:
  default:
    name: rag-dev
    driver: bridge

volumes:
  pgdata:
