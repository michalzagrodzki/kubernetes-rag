services:
  postgres_dev:
    image: pgvector/pgvector:pg16
    container_name: postgres_dev
    restart: unless-stopped
    ports:
      - "${POSTGRES_HOST_PORT:-5432}:5432"
    env_file:
      - .env.postgres
    environment:
      POSTGRES_DB: ${POSTGRES_DB:-ragdb}
      POSTGRES_USER: ${POSTGRES_USER:-rag}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-ragpassword}
    volumes:
      - pgdata:/var/lib/postgresql/data
    healthcheck:
      test:
        ["CMD-SHELL", 'pg_isready -U "$${POSTGRES_USER}" -d "$${POSTGRES_DB}"']
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s

  backend_dev:
    build:
      context: .
      dockerfile: deploy/containers/Dockerfile.backend
      tags:
        - rag-backend:dev
      platforms:
        - linux/arm64
    container_name: backend_dev
    restart: unless-stopped
    ports:
      - "8000:8000"
    env_file:
      - backend/.env
      - .env.postgres
    environment:
      TEI_BASE_URL: http://embedding_dev:80
      LOCAL_LLM_BASE_URL: http://llm_dev:8000/v1
    platform: linux/arm64
    volumes:
      - ./backend/pdfs:/app/pdfs
      - ./backend:/app
    depends_on:
      - postgres_dev
      - embedding_dev
      - llm_dev

  frontend_dev:
    build:
      context: .
      dockerfile: deploy/containers/Dockerfile.frontend
      tags:
        - rag-frontend:dev
      platforms:
        - linux/arm64
      args:
        VITE_API_URL: http://backend_dev:8000
    container_name: frontend_dev
    restart: unless-stopped
    ports:
      - "8080:8080"
    platform: linux/arm64
    environment:
      BACKEND_URL: http://backend_dev:8000
    depends_on:
      - backend_dev

  embedding_dev:
    image: ghcr.io/huggingface/text-embeddings-inference:cpu-1.8
    platform: linux/amd64
    container_name: embedding_dev
    restart: unless-stopped
    ports:
      - "7070:80"
    volumes:
      - ${TEI_MODEL_DIR:-$HOME/rag-tei/models}:/data
    environment:
      MODEL_ID: /data/nomic-embed-text-v1.5

  llm_dev:
    build:
      context: .
      dockerfile: deploy/containers/Dockerfile.llamacpp
    container_name: llm_dev
    restart: unless-stopped
    ports:
      - "8081:8000"
    environment:
      HOST: 0.0.0.0
      PORT: 8000

networks:
  default:
    name: rag-dev
    driver: bridge

volumes:
  pgdata:
